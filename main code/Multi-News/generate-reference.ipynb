{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_dirs = []\n",
    "path = './multi-news-original/test.tgt'\n",
    "f_path = open(path, 'r', encoding='utf-8')\n",
    "for lines in f_path:\n",
    "    lines = lines.strip('\\n')\n",
    "    reference_dirs.append(lines)\n",
    "f_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dirindex_path.txt file.\n",
    "\n",
    "dir_index_path = {}\n",
    "f_dirpath = open('dirindex_path.txt', 'r', encoding='utf-8')\n",
    "for sents in f_dirpath:\n",
    "    sents = sents.strip('\\n')\n",
    "    item1 = sents.split(':')\n",
    "    dir_index_path[int(item1[0])] = item1[1]\n",
    "f_dirpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sents_dirs = []\n",
    "for i in dir_index_path: \n",
    "    reference_one = reference_dirs[int(dir_index_path[i])]\n",
    "    reference_one1 = reference_one.strip('â€“')\n",
    "    reference_sents_one = []\n",
    "    item0_str = ''\n",
    "    item0_str = ' '.join(reference_one1.split())\n",
    "    sents = nltk.sent_tokenize(item0_str)\n",
    "    for item in sents:\n",
    "        reference_sents_one.append(item)\n",
    "    reference_sents_dirs.append(reference_sents_one)\n",
    "    \n",
    "    onetext = \"./reference_sents/\" + str(i) + '.txt'\n",
    "    f_onetext = open(onetext, 'w')\n",
    "    for items_temp in reference_sents_one:\n",
    "        f_onetext.writelines(items_temp)\n",
    "        f_onetext.write('\\n')\n",
    "    f_onetext.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_py38",
   "language": "python",
   "name": "tf2_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
