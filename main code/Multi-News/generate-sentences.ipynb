{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinews_dirs = []\n",
    "path = './multi-news-original-src-cleaned/test.src.cleaned'\n",
    "f_path = open(path, 'r', encoding='utf-8')\n",
    "for lines in f_path:\n",
    "    lines = lines.strip('\\n')\n",
    "    multinews_dirs.append(lines)\n",
    "f_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinews_dir_doc = []\n",
    "for item in multinews_dirs:\n",
    "    multinews_dir_doc_one = []\n",
    "    item_list = item.split('|||||')\n",
    "    for item0 in item_list:\n",
    "        if len(item0) != 0:\n",
    "            multinews_dir_doc_one.append(item0)\n",
    "    multinews_dir_doc.append(multinews_dir_doc_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_docs = [850, 5620]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_dirs = []\n",
    "\n",
    "dir_index = 0\n",
    "dir_index_path = {}\n",
    "doc_index_path = {}\n",
    "for i in range(len(multinews_dir_doc)):\n",
    "    if len(multinews_dir_doc[i]) == 0:\n",
    "        continue\n",
    "    if i in noise_docs:\n",
    "        continue\n",
    "        \n",
    "    pathdir = \"./duc_sents/\" + str(dir_index)\n",
    "    if not os.path.exists(pathdir):\n",
    "        os.mkdir(pathdir)\n",
    "    dir_index_path[dir_index] = i\n",
    "        \n",
    "    sents_dirone = []\n",
    "    doc_index_path[dir_index] = {}\n",
    "    for j in range(len(multinews_dir_doc[i])):\n",
    "        doc_index_path[dir_index][j] = j\n",
    "        sents_docone = []\n",
    "        doc_one1 = multinews_dir_doc[i][j].split('NEWLINE_CHAR NEWLINE_CHAR')\n",
    "        for item0 in doc_one1:\n",
    "            item0_str = ''\n",
    "            item0_str = ' '.join(item0.split())\n",
    "            sents = nltk.sent_tokenize(item0_str)\n",
    "            for item1 in sents:\n",
    "                sents_docone.append(item1)\n",
    "        sents_dirone.append(sents_docone)\n",
    "        \n",
    "        onetext = pathdir + '/duc' + str(j) + '.txt'\n",
    "        f_onetext = open(onetext, 'w')\n",
    "        for items_temp in sents_docone:\n",
    "            f_onetext.writelines(items_temp)\n",
    "            f_onetext.write('\\n')\n",
    "        f_onetext.close()\n",
    "    sents_dirs.append(sents_dirone)\n",
    "    \n",
    "    dir_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dirpath = open('dirindex_path.txt', 'w')\n",
    "for item_temp in dir_index_path.keys():\n",
    "    f_dirpath.writelines(str(item_temp))\n",
    "    f_dirpath.writelines(':')\n",
    "    f_dirpath.writelines(str(dir_index_path[item_temp]))\n",
    "    f_dirpath.write('\\n')\n",
    "f_dirpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_docpath = open('docindex_path.txt', 'w')\n",
    "for item_temp in doc_index_path.keys():\n",
    "    for word_temp in doc_index_path[item_temp]:\n",
    "        f_docpath.writelines(str(item_temp))\n",
    "        f_docpath.writelines(':')\n",
    "        f_docpath.writelines(str(word_temp))\n",
    "        f_docpath.writelines(':')\n",
    "        f_docpath.writelines(str(doc_index_path[item_temp][word_temp]))\n",
    "        f_docpath.write('\\n')\n",
    "f_docpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_py38",
   "language": "python",
   "name": "tf2_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
