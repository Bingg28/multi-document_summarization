{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "import math\n",
    "\n",
    "from nltk.tree import Tree\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from pythonrouge.pythonrouge import Pythonrouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取（dirindex_path.txt）文件。\n",
    "\n",
    "dir_index_path = {}\n",
    "f_dirpath = open('dirindex_path.txt', 'r', encoding='utf-8')\n",
    "for sents in f_dirpath:\n",
    "    sents = sents.strip('\\n')\n",
    "    item1 = sents.split(':')\n",
    "    dir_index_path[int(item1[0])] = item1[1]\n",
    "f_dirpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取（docindex_path.txt）文件。\n",
    "\n",
    "doc_index_path = {}\n",
    "f_docpath = open('docindex_path.txt', 'r', encoding='utf-8')\n",
    "for sents in f_docpath:\n",
    "    sents = sents.strip('\\n')\n",
    "    item1 = sents.split(':')\n",
    "    if int(item1[0]) not in doc_index_path:\n",
    "        doc_index_path[int(item1[0])] = {}\n",
    "        doc_index_path[int(item1[0])][int(item1[1])] = item1[2]\n",
    "    else:\n",
    "        doc_index_path[int(item1[0])][int(item1[1])] = item1[2]\n",
    "f_docpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clufinal_ans_alldir = []\n",
    "summarys_alldir = {}\n",
    "reference_alldir = {}\n",
    "\n",
    "for dir_i in range(len(dir_index_path)):\n",
    "    # 每个文件夹\n",
    "    \n",
    "    #(tf2_py38环境下)\n",
    "    %run clustering-summarization-run.ipynb\n",
    "    \n",
    "    summarys_alldir[dir_i] = summarys\n",
    "    reference_alldir[dir_i] = reference_one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarys_all = []\n",
    "for item in summarys_alldir:\n",
    "    summarys_all.append(summarys_alldir[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_all = []\n",
    "for item in reference_alldir:\n",
    "    reference_all_one = []\n",
    "    reference_all_one.append(reference_alldir[item])\n",
    "    reference_all.append(reference_all_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出所有文件夹的Rouge打分。\n",
    "    \n",
    "rouge = Pythonrouge(summary_file_exist=False,\n",
    "                    summary=summarys_all, reference=reference_all,\n",
    "                    n_gram=2, ROUGE_SU4=True, ROUGE_L=True,\n",
    "                    recall_only=False, stemming=True, stopwords=False,\n",
    "                    word_level=True, length_limit=True, length=264,\n",
    "                    use_cf=False, cf=95, scoring_formula='average',\n",
    "                    resampling=True, samples=1000, favor=True, p=0.5)\n",
    "\n",
    "score = rouge.calc_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_py38",
   "language": "python",
   "name": "tf2_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
