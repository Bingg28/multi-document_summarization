{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'duc2002'\n",
    "files = os.listdir(path)\n",
    "\n",
    "dir_index = 0\n",
    "dir_index_path = {}\n",
    "doc_index_path = {}\n",
    "\n",
    "sents_papers = []\n",
    "\n",
    "for file in files:\n",
    "    if not os.path.isdir(path + \"/\" + file):\n",
    "        print(\"ERROR!!! This file is not a folder！！！\")\n",
    "        continue\n",
    "    \n",
    "    pathdir = \"./duc_sents/\" + str(dir_index)\n",
    "    if not os.path.exists(pathdir):\n",
    "        os.mkdir(pathdir)\n",
    "    \n",
    "    path1 = path + \"/\" + file\n",
    "    dir_index_path[dir_index] = file\n",
    "    \n",
    "    files1 = os.listdir(path1)\n",
    "    doc_index = 0\n",
    "    doc_index_path[dir_index] = {}\n",
    "    for file1 in files1:\n",
    "        doc_index_path[dir_index][doc_index] = file1\n",
    "        path2 = path1 + \"/\" + file1\n",
    "        if os.path.isdir(path2):\n",
    "            print(\"ERROR!!!!!! This file is a folder！！！\")\n",
    "            continue\n",
    "        with open(path2,'r') as foo_file :\n",
    "            soup = BeautifulSoup(foo_file, 'html.parser')\n",
    "\n",
    "        f = []\n",
    "        txt = soup.find_all('text')\n",
    "        for item in txt:\n",
    "            f.append(item.get_text())\n",
    "\n",
    "        con = []\n",
    "        for item in f:\n",
    "            item = item.replace('\\n',' ')\n",
    "            item_str = ''\n",
    "            item_str = ' '.join(item.split())\n",
    "            con.append(item_str)\n",
    "\n",
    "        sents_onepaper = {}\n",
    "        for j in range(len(con)):\n",
    "            sents = nltk.sent_tokenize(con[j])\n",
    "            for k in range(len(sents)):\n",
    "                sents_onepaper[k] = sents[k]\n",
    "        sents_papers.append(sents_onepaper)\n",
    "\n",
    "        onetext = pathdir + '/duc' + str(doc_index) + '.txt'\n",
    "        f_onetext = open(onetext, 'w')\n",
    "        for items_temp in sents_onepaper.keys():\n",
    "            f_onetext.writelines(sents_onepaper[items_temp])\n",
    "            f_onetext.write('\\n')\n",
    "        f_onetext.close()\n",
    "\n",
    "        doc_index += 1\n",
    "    dir_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dirpath = open('dirindex_path.txt', 'w')\n",
    "for item_temp in dir_index_path.keys():\n",
    "    f_dirpath.writelines(str(item_temp))\n",
    "    f_dirpath.writelines(':')\n",
    "    f_dirpath.writelines(dir_index_path[item_temp])\n",
    "    f_dirpath.write('\\n')\n",
    "f_dirpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_docpath = open('docindex_path.txt', 'w')\n",
    "for item_temp in doc_index_path.keys():\n",
    "    for word_temp in doc_index_path[item_temp]:\n",
    "        f_docpath.writelines(str(item_temp))\n",
    "        f_docpath.writelines(':')\n",
    "        f_docpath.writelines(str(word_temp))\n",
    "        f_docpath.writelines(':')\n",
    "        f_docpath.writelines(doc_index_path[item_temp][word_temp])\n",
    "        f_docpath.write('\\n')\n",
    "f_docpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_py38",
   "language": "python",
   "name": "tf2_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
