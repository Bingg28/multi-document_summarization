{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "import math\n",
    "\n",
    "from nltk.tree import Tree\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from pythonrouge.pythonrouge import Pythonrouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dirindex_path.txt file.\n",
    "\n",
    "dir_index_path = {}\n",
    "f_dirpath = open('dirindex_path.txt', 'r', encoding='utf-8')\n",
    "for sents in f_dirpath:\n",
    "    sents = sents.strip('\\n')\n",
    "    item1 = sents.split(':')\n",
    "    dir_index_path[int(item1[0])] = item1[1]\n",
    "f_dirpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read docindex_path.txt file.\n",
    "\n",
    "doc_index_path = {}\n",
    "f_docpath = open('docindex_path.txt', 'r', encoding='utf-8')\n",
    "for sents in f_docpath:\n",
    "    sents = sents.strip('\\n')\n",
    "    item1 = sents.split(':')\n",
    "    if int(item1[0]) not in doc_index_path:\n",
    "        doc_index_path[int(item1[0])] = {}\n",
    "        doc_index_path[int(item1[0])][int(item1[1])] = item1[2]\n",
    "    else:\n",
    "        doc_index_path[int(item1[0])][int(item1[1])] = item1[2]\n",
    "f_docpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clufinal_ans_alldir = []\n",
    "summarys_alldir = []\n",
    "\n",
    "for dir_i in range(len(dir_index_path)):\n",
    "    # each folder\n",
    "    \n",
    "    %run clustering-summarization-run.ipynb\n",
    "    \n",
    "    summarys_alldir.append(summarys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'evaluation_results/abstracts/phase1/SEEmodels/SEE.edited.abstracts.in.edus'\n",
    "files = os.listdir(path)\n",
    "reference_filedic = {}\n",
    "symbols = {'[1]','[2]','[3]','[4]','[5]','[6]','[7]','[8]','[9]','[10]','[11]','[12]','[13]','[14]','[15]','[16]','[17]','[18]','[19]','[20]','[21]','[22]','[23]','[24]','[25]','[26]','[27]'}\n",
    "for file in files:\n",
    "    if file == '.DS_Store':\n",
    "        continue\n",
    "    file_list = file.split('.')\n",
    "    file_list[0] = file_list[0][1:]\n",
    "    one_path = path + \"/\" + file\n",
    "    with open(one_path,'r',encoding='utf-8') as foo_file :\n",
    "        soup = BeautifulSoup(foo_file)\n",
    "        \n",
    "    summary_fileone = []    \n",
    "    \n",
    "    f = []\n",
    "    txt = soup.find_all('body')\n",
    "    for item in txt:\n",
    "        f.append(item.get_text())\n",
    "        \n",
    "    con = []\n",
    "    for item in f:\n",
    "        item = item.replace('\\n',' ')\n",
    "        for word in symbols:\n",
    "            item = item.replace(word,' ')\n",
    "        item_str = ''\n",
    "        item_str = ' '.join(item.split())\n",
    "        con.append(item_str)\n",
    "    \n",
    "    for j in range(len(con)):\n",
    "        sents = nltk.sent_tokenize(con[j])\n",
    "        for item0 in sents:\n",
    "            summary_fileone.append(item0)\n",
    "    \n",
    "    if file_list[0] not in reference_filedic:\n",
    "        reference_filedic[file_list[0]] = {}\n",
    "        if file_list[1] == 'M':\n",
    "            if file_list[2] not in reference_filedic[file_list[0]]:\n",
    "                reference_filedic[file_list[0]][file_list[2]] = []\n",
    "                reference_filedic[file_list[0]][file_list[2]].append(summary_fileone)\n",
    "            else:\n",
    "                reference_filedic[file_list[0]][file_list[2]].append(summary_fileone)\n",
    "    else:\n",
    "        if file_list[1] == 'M':\n",
    "            if file_list[2] not in reference_filedic[file_list[0]]:\n",
    "                reference_filedic[file_list[0]][file_list[2]] = []\n",
    "                reference_filedic[file_list[0]][file_list[2]].append(summary_fileone)\n",
    "            else:\n",
    "                reference_filedic[file_list[0]][file_list[2]].append(summary_fileone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_alldir = []\n",
    "for dir_i in range(len(dir_index_path)):\n",
    "    reference_alldir.append(reference_filedic[dir_index_path[dir_i][1:-1]]['100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output average Rouge scores of all folders.\n",
    "    \n",
    "rouge = Pythonrouge(summary_file_exist=False,\n",
    "                    summary=summarys_alldir, reference=reference_alldir,\n",
    "                    n_gram=2, ROUGE_SU4=True, ROUGE_L=True,\n",
    "                    recall_only=True, stemming=True, stopwords=False,\n",
    "                    word_level=True, length_limit=True, length=100,\n",
    "                    use_cf=False, cf=95, scoring_formula='average',\n",
    "                    resampling=True, samples=1000, favor=True, p=0.5)\n",
    "\n",
    "score = rouge.calc_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_py38",
   "language": "python",
   "name": "tf2_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
