{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "import math\n",
    "\n",
    "from nltk.tree import Tree\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import random\n",
    "\n",
    "from pythonrouge.pythonrouge import Pythonrouge\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dirindex_path.txt file.\n",
    "\n",
    "dir_index_path = {}\n",
    "f_dirpath = open('dirindex_path.txt', 'r', encoding='utf-8')\n",
    "for sents in f_dirpath:\n",
    "    sents = sents.strip('\\n')\n",
    "    item1 = sents.split(':')\n",
    "    dir_index_path[int(item1[0])] = item1[1]\n",
    "f_dirpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read docindex_path.txt file\n",
    "\n",
    "doc_index_path = {}\n",
    "f_docpath = open('docindex_path.txt', 'r', encoding='utf-8')\n",
    "for sents in f_docpath:\n",
    "    sents = sents.strip('\\n')\n",
    "    item1 = sents.split(':')\n",
    "    if int(item1[0]) not in doc_index_path:\n",
    "        doc_index_path[int(item1[0])] = {}\n",
    "        doc_index_path[int(item1[0])][int(item1[1])] = item1[2]\n",
    "    else:\n",
    "        doc_index_path[int(item1[0])][int(item1[1])] = item1[2]\n",
    "f_docpath.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir_index = {4929, 4674, 1123, 5284, 4136, 906, 1488, 2513, 3123, 3156, 2199, 187, 4092, 2811,22,0,4036,4108,3705,4105,4134,3866,3727,2508,513}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_all = {}\n",
    "threshold1_list = [2,3,4]\n",
    "threshold2_list = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "for threshold1 in threshold1_list:\n",
    "    for threshold2 in threshold2_list:\n",
    "        threshold12_str = str(threshold1) + ',' + str(threshold2)\n",
    "        %run evaluation_one.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_all_metSort = {}\n",
    "scores_all_met = {}\n",
    "for thri in scores_all:\n",
    "    for meti in scores_all[thri]:\n",
    "        if meti not in scores_all_met:\n",
    "            scores_all_met[meti] = {}\n",
    "            scores_all_met[meti][thri] = scores_all[thri][meti]\n",
    "        else:\n",
    "            scores_all_met[meti][thri] = scores_all[thri][meti]\n",
    "for meti in scores_all_met:\n",
    "    scores_all_metSort[meti] = sorted(scores_all_met[meti].items(),key = lambda x:x[1],reverse = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathdir2 = './scores_val.txt'\n",
    "f_onetext2 = open(pathdir2, 'w')\n",
    "f_onetext2.write(str(val_dir_index))\n",
    "f_onetext2.write('\\n')\n",
    "for thri in scores_all:\n",
    "    f_onetext2.write(thri)\n",
    "    f_onetext2.write(':')\n",
    "    f_onetext2.write(str(scores_all[thri]))\n",
    "    f_onetext2.write('\\n')\n",
    "f_onetext2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_py38",
   "language": "python",
   "name": "tf2_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
